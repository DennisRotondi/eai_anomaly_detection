{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# [PG01] Unsupervised anomaly detection in industrial image data with autoencoders"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["In this notebook we are going to develop the final projet for the EAI course held by Christian Napoli."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Imports & Download"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# install the requirements\n","%pip install -r requirements.txt > /dev/null\n","# set to false if you already have the dataset\n","download_dataset = False \n","if download_dataset:\n","    %cd dataset\n","    !bash dataset/download_dataset.sh\n","    %cd .."]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Global seed set to 0\n"]},{"name":"stdout","output_type":"stream","text":["The autoreload extension is already loaded. To reload it, use:\n","  %reload_ext autoreload\n"]}],"source":["import dataclasses\n","from src.data_module import MVTec_Dataset, MVTec_DataModule\n","from src.AE_simple import AE\n","from src.hyperparameters import Hparams\n","from dataclasses import asdict\n","import matplotlib.pyplot as plt\n","import wandb\n","import torchvision\n","import pytorch_lightning as pl\n","from pytorch_lightning.loggers.wandb import WandbLogger\n","from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n","from pytorch_lightning.callbacks import ModelCheckpoint\n","# reproducibility stuff\n","import numpy as np\n","import random\n","import torch\n","np.random.seed(0)\n","random.seed(0)\n","torch.cuda.manual_seed(0)\n","torch.manual_seed(0)\n","torch.backends.cudnn.deterministic = True  # Note that this Deterministic mode can have a performance impact\n","torch.backends.cudnn.benchmark = False\n","_ = pl.seed_everything(0)\n","wandb.require(\"service\")\n","\n","# to have a better workflow using notebook https://stackoverflow.com/questions/5364050/reloading-submodules-in-ipython\n","# these commands allow to update the .py codes imported instead of re-importing everything every time.\n","%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# login wandb to have the online logger. It is really useful since it stores all the plots and evolution of the model\n","# check also https://docs.wandb.ai/guides/integrations/lightning\n","wandb.login()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Dataset test"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Just to have a visual feedback and test our code, we plot some samples from the training set (only not anomalous samples) and test set (normal and anomalous)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["hparams = asdict(Hparams())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["MVTec_Data = MVTec_DataModule(hparams)\n","# to setup it takes ~2.5 minutes\n","MVTec_Data.setup()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# to make sure everything works we just plot a sample of our images\n","def plot_objects(images, \n","                images_per_row, \n","                border = 10, \n","                pad_value = 1,\n","                title = 'Industrial images',\n","                figsize = (16,16)):\n","    plt.figure(figsize = figsize)\n","    plt.imshow(torchvision.utils.make_grid(images,images_per_row,border,pad_value=pad_value).permute(1, 2, 0))\n","    plt.title(title)\n","    plt.axis('off')\n","\n","batch = iter(MVTec_Data.train_dataloader()).next()\n","plot_objects(batch[\"img\"][0:40], images_per_row=8, title=\"Industrial images from training dataset\")\n","batch2 = iter(MVTec_Data.val_dataloader()).next()\n","plot_objects(batch2[\"img\"][0:40], images_per_row=8, title=\"Industrial images from validation dataset\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["todo some statistics on the pixels of the training dataset to do a proper normalization"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Autoencoders"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["# this function encapsulate the stuff (logger, callbacks, parameters)\n","# needed to perform the pytorch lightning training for each model\n","def train_model(data, model, experiment_name, model_version, patience, metric_to_monitor, mode, epochs):\n","    logger =  WandbLogger(project=experiment_name, name = model_version, log_model=True, save_dir=\"logs\")\n","    logger.experiment.watch(model, log = None, log_freq = 100000)\n","    # To limit overfitting and avoid much more epochs than needed to complete\n","    # the training, we use the early stopping regulation technique which is\n","    # very powerful since it controls whether there is an improvement in the\n","    # model or not. If there is no improvement in the model performances for a \n","    # given number of epochs (patience) on a certain metric (metric_to_monitor)\n","    # then the training stops.\n","    early_stop_callback = EarlyStopping(\n","        monitor=metric_to_monitor, mode=mode, min_delta=0.00,\n","        patience=patience, verbose=True)\n","    checkpoint_callback = ModelCheckpoint(\n","        save_top_k=1, monitor=metric_to_monitor, mode=mode, dirpath=\"models\",\n","        filename=experiment_name + \"_\" + model_version +\n","        \"-{epoch:02d}-{avg_val_loss:.4f}\", verbose=True)\n","    # the trainer collect all the useful informations so far for the training\n","    n_gpus = 1 if torch.cuda.is_available() else 0\n","    trainer = pl.Trainer(\n","        logger=logger, max_epochs=epochs, log_every_n_steps=1, gpus=n_gpus,\n","        callbacks=[early_stop_callback, checkpoint_callback],\n","        num_sanity_val_steps=0)\n","    trainer.fit(model, data)\n","    wandb.finish()\n","    return trainer\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### CNN-AE l2 deterministic"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["GPU available: True, used: True\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","HPU available: False, using: 0 HPUs\n"]}],"source":["ae_hparams = asdict(Hparams())\n","data = MVTec_DataModule(ae_hparams)\n","model = AE(ae_hparams)\n","trainer = train_model(data,model, \"EAI_ANOMALY_DET\", \"Simple_AE_01\", patience= 15, metric_to_monitor=\"loss\", mode=\"min\", epochs = 100)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["sYnPaW3xqB76","o_pOiPmDqB78","UM9r2JPLqB79","dWYN7dXdqB7_","-6AfNu4BqB8A","8qebcYffqB8A","jGyjEQYeqB8B","3rN7DegMJpJB","P8ThCPp6Jt5c","7_K0zpGyqB8H","iCFsRmN9qB8I"],"provenance":[],"toc_visible":true},"gpuClass":"standard","kernelspec":{"display_name":"dlp","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"vscode":{"interpreter":{"hash":"47190f7cb2772d39fc79edc4ccd16e1d5aa2f435aeaf1de6cf1f85c03f1e696f"}}},"nbformat":4,"nbformat_minor":0}
