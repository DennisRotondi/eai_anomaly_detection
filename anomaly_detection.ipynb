{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# [PG01] Unsupervised anomaly detection in industrial image data with autoencoders"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["> In this notebook we are going to develop the final projet for the *EAI course* held by Christian Napoli. The *dataset* is the well know **MVtec AD** described in the paper that has been referenced on our report. For this reason we won't spend much time in replicating the *analysis* and *statistics* that can be found on the original article."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Imports & Download"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# install the requirements\n","%pip install -r requirements.txt > /dev/null\n","# set to false if you already have the dataset\n","download_dataset = False \n","if download_dataset:\n","    %cd dataset\n","    !bash dataset/download_dataset.sh\n","    %cd .."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import dataclasses\n","from src.data_module import MVTec_Dataset, MVTec_DataModule\n","from src.AE_simple import AE\n","from src.AE_CODE import CODE_AE\n","from src.hyperparameters import Hparams\n","from src.train import train_model\n","from dataclasses import asdict\n","import matplotlib.pyplot as plt\n","import wandb\n","import torchvision\n","import pytorch_lightning as pl\n","import gc\n","# reproducibility stuff\n","import numpy as np\n","import random\n","import torch\n","np.random.seed(0)\n","random.seed(0)\n","torch.cuda.manual_seed(0)\n","torch.manual_seed(0)\n","torch.backends.cudnn.deterministic = True  # Note that this Deterministic mode can have a performance impact\n","torch.backends.cudnn.benchmark = False\n","_ = pl.seed_everything(0)\n","# to have a better workflow using notebook https://stackoverflow.com/questions/5364050/reloading-submodules-in-ipython\n","# these commands allow to update the .py codes imported instead of re-importing everything every time.\n","%load_ext autoreload\n","%autoreload 2\n","%env WANDB_NOTEBOOK_NAME = ./anomaly_detection.ipynb\n","gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# login wandb to have the online logger. It is really useful since it stores all the plots and evolution of the model\n","# check also https://docs.wandb.ai/guides/integrations/lightning\n","wandb.login()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Utilities"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# to make sure everything works we just plot a sample of our images\n","def plot_objects(images, \n","                images_per_row, \n","                border = 10, \n","                pad_value = 1,\n","                title = 'Industrial images',\n","                figsize = (16,16)):\n","    plt.figure(figsize = figsize)\n","    plt.imshow(torchvision.utils.make_grid(images,images_per_row,border,pad_value=pad_value).permute(1, 2, 0))\n","    plt.title(title)\n","    plt.axis('off')\n","\n","# todo evaluate performance on the different input classes to understand which is performing better"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Dataset"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["> Just to have a visual feedback and test our code, we plot some samples from the **train** set (only *normal* samples) and **test** set (*normal* and *anomalous*)."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["hparams = asdict(Hparams())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["MVTec_Data = MVTec_DataModule(hparams)\n","# to setup it takes ~3 minutes\n","MVTec_Data.setup()\n","print(len(MVTec_Data.data_train)) # -->  3629 images\n","print(len(MVTec_Data.data_test)) # -->  1258+467=1725 images\n","print(\"TOTAL: \"+str(len(MVTec_Data.data_train)+len(MVTec_Data.data_test))+\" industrial images\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# depending on python version you can use --> data = iter(dataloader).next() or\n","#                                             data = next(iter(dataloader))\n","batch = next(iter(MVTec_Data.train_dataloader()))\n","plot_objects(MVTec_DataModule.denormalize(batch[\"img\"][0:40]), images_per_row=8, title=\"Industrial images from training dataset\")\n","batch2 = next(iter(MVTec_Data.val_dataloader()))\n","plot_objects(MVTec_DataModule.denormalize(batch2[\"img\"][0:40]), images_per_row=8, title=\"Industrial images from validation dataset\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["> âš¡ During our implementation we also tried an additional data extraction strategy in order to make ***data.setup()*** more efficient. <br> At the beginning we thought the slowness of the operation was induced by the many folder accesses and as a result the dataset folder structure is been modified. <br> Unfortunately *NO IMPROVEMENTS* were achieved. In fact the lack of efficiency came from the *image transformations*!"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Autoencoders - **AE**"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Baseline - *CNN AE*"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# settings for the logger working in a team\n","team_name = \"eai_project\"\n","project_name = \"EAI_Anomaly_Detection\"\n","version_name = \"baseline_1\"\n","run = wandb.init(entity=team_name, project=project_name, name = version_name, mode = \"offline\")\n","\n","ae_hparams = asdict(Hparams())\n","data = MVTec_DataModule(ae_hparams)\n","model = AE(ae_hparams)\n","trainer = train_model(data, model, ae_hparams[\"batch_size\"], experiment_name = version_name, patience=20, metric_to_monitor=\"auroc\", mode=\"max\", epochs = 100)\n","\n","wandb.finish()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### CNN Advanced AE - ***CO**ntractive + **DE**noising*"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# settings for the logger working in a team\n","team_name = \"eai_project\"\n","project_name = \"EAI_Anomaly_Detection\"\n","# to edit \n","version_name = \"advanced_AE_2\"\n","run = wandb.init(entity=team_name, project=project_name, name = version_name, mode = \"offline\")\n","\n","ae_hparams = asdict(Hparams())\n","data = MVTec_DataModule(ae_hparams)\n","model = CODE_AE(ae_hparams)\n","trainer = train_model(data,model, experiment_name = version_name, patience=20, metric_to_monitor=\"f1_score\", mode=\"max\", epochs = 150)\n","\n","wandb.finish()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Test and analysis"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# best_ckpt = \"models/Simple_AE_01-epoch=71-avg_val_loss=0.0278.ckpt\"\n","# model = AE.load_from_checkpoint(best_ckpt, strict=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["batch = iter(data.train_dataloader()).next()\n","plot_objects(MVTec_DataModule.denormalize(batch[\"img\"][0:40]), images_per_row=8, title=\"Industrial images from training dataset\")\n","\n","batch_recon = model(batch[\"img\"])\n","plot_objects(MVTec_DataModule.denormalize(batch_recon[0:40]), images_per_row=8, title=\"Industrial images from training dataset (reconstructed)\")"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["sYnPaW3xqB76","o_pOiPmDqB78","UM9r2JPLqB79","dWYN7dXdqB7_","-6AfNu4BqB8A","8qebcYffqB8A","jGyjEQYeqB8B","3rN7DegMJpJB","P8ThCPp6Jt5c","7_K0zpGyqB8H","iCFsRmN9qB8I"],"provenance":[],"toc_visible":true},"gpuClass":"standard","kernelspec":{"display_name":"sappia","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"},"vscode":{"interpreter":{"hash":"5f06e66338bb5301debc8a4cff3b178f3ee2a0c1aca00670585ce1ed8b6c95da"}}},"nbformat":4,"nbformat_minor":0}
