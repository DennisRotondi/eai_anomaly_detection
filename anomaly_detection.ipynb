{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# [PG01] Unsupervised anomaly detection in industrial image data with autoencoders"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["> In this notebook we are going to develop the final projet for the *EAI course* held by Christian Napoli. The *dataset* is the well know **MVtec AD** described in the paper that has been referenced on our report. For this reason we won't spend much time in replicating the *analysis* and *statistics* that can be found on the original article."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Imports & Download"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# install the requirements\n","%pip install -r requirements.txt > /dev/null\n","# set to false if you already have the dataset\n","download_dataset = False \n","if download_dataset:\n","    %cd dataset\n","    !bash dataset/download_dataset.sh\n","    %cd .."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import dataclasses\n","from src.data_module import MVTec_Dataset, MVTec_DataModule\n","from src.AE_simple import AE\n","from src.AE_CODE import CODE_AE\n","from src.AE_mixer import Mixer_AE\n","from src.hyperparameters import Hparams\n","from src.train import train_model\n","from dataclasses import asdict\n","import matplotlib.pyplot as plt\n","import wandb\n","import torchvision\n","import pytorch_lightning as pl\n","import gc\n","from collections import Counter\n","import seaborn as sns\n","# reproducibility stuff\n","import numpy as np\n","import random\n","import torch\n","np.random.seed(0)\n","random.seed(0)\n","torch.cuda.manual_seed(0)\n","torch.manual_seed(0)\n","torch.backends.cudnn.deterministic = True  # Note that this Deterministic mode can have a performance impact\n","torch.backends.cudnn.benchmark = False\n","_ = pl.seed_everything(0)\n","# to have a better workflow using notebook https://stackoverflow.com/questions/5364050/reloading-submodules-in-ipython\n","# these commands allow to update the .py codes imported instead of re-importing everything every time.\n","%load_ext autoreload\n","%autoreload 2\n","%env WANDB_NOTEBOOK_NAME = ./anomaly_detection.ipynb\n","gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# login wandb to have the online logger. It is really useful since it stores all the plots and evolution of the model\n","# check also https://docs.wandb.ai/guides/integrations/lightning\n","wandb.login()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Utilities"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# to make sure everything works we just plot a sample of our images\n","def plot_objects(images, \n","                images_per_row, \n","                border = 10, \n","                pad_value = 1,\n","                title = 'Industrial images',\n","                figsize = (16,16)):\n","    plt.figure(figsize = figsize)\n","    plt.imshow(torchvision.utils.make_grid(images,images_per_row,border,pad_value=pad_value).permute(1, 2, 0))\n","    plt.title(title)\n","    plt.axis('off')\n","\n","from tqdm import tqdm\n","# these are the performance we metric we compute to compare them with the 2019 MVTec paper results.\n","# Two metrics are needed:\n","# - accuracy of objects predicted as anomaly. --> it's exactly the recall\n","# - accuracy of objects predicted as normal. --> it's a different metrics --> T_normal / T_normal+F_anomaly\n","# POSITIVES are anomalies and NEGATIVES are the normal instances\n","def performance_evaluation(model, dataset):\n","    model.eval()\n","    c2id = dataset.c2id # class to id\n","    id2c = dataset.id2c # id to class\n","    # we  utilize Counter() because we compute the metrics for each category class!\n","    total_anom = Counter() # TP+FN\n","    total_norm = Counter() # TN+FP\n","    total_predicted_anom = Counter() # TP+FP\n","    true_anom = Counter() # TP\n","    true_norm = Counter() # TN\n","    with torch.no_grad():\n","        for batch in tqdm(dataset.val_dataloader()):\n","            pred = model.anomaly_prediction(batch[\"img\"])\n","            true_anomaly_mask = batch[\"label\"]>0 # True if is an anomaly --> returns a list [T,F,F,T,F,...]\n","            true_normal_mask = batch[\"label\"]==0 # True if is an anomaly-free instance\n","            pred_fila = pred>0\n","            total_anom.update([id2c[i] for i in batch[\"class_obj\"][true_anomaly_mask].tolist()]) # {\"tile\":2, \"carpet\":3, ...}\n","            total_norm.update([id2c[i] for i in batch[\"class_obj\"][true_normal_mask].tolist()])\n","            total_predicted_anom.update([id2c[i] for i in batch[\"class_obj\"][pred_fila].tolist()])\n","            \n","            pred_good_mask = batch[\"label\"]==pred\n","            pred_anomaly = pred==1\n","            pred_normal = pred==0\n","            true_anom.update([id2c[i] for i in batch[\"class_obj\"][torch.logical_and(pred_good_mask, pred_anomaly)].tolist()])\n","            true_norm.update([id2c[i] for i in batch[\"class_obj\"][torch.logical_and(pred_good_mask, pred_normal)].tolist()])\n","            \n","        tot_conf_matrix = np.array([[0,0],[0,0]])\n","        for k in total_anom.keys(): # for each class k\n","            all_a_k = total_anom[k]\n","            all_n_k = total_norm[k]\n","            all_pred_a_k= total_predicted_anom[k]\n","            class_total = all_a_k + all_n_k\n","            true_a_k = true_anom[k]\n","            true_n_k = true_norm[k]\n","            \n","            precision = true_a_k / all_pred_a_k\n","            recall = true_a_k / all_a_k\n","            f1_score = 2*precision*recall/(precision+recall)\n","            #print(f\"there are {class_total} {k}, anomaly-free predicted correctly {true_n_k/all_n_k:.3f}, anomalies predicted correctly {true_a_k/all_a_k:.3f}, f1_score {f1_score:.3f}\")\n","            \n","            print(\"[\"+k.upper()+\"]\")\n","            print(f\"Total number: {class_total}\")\n","            print(f\"anomaly-free predicted correctly: {true_n_k/all_n_k:.3f}\")\n","            print(f\"anomalies predicted correctly: {true_a_k/all_a_k:.3f}\")\n","            print(f\"f1_score: {true_n_k/f1_score:.3f}\")\n","            print(\"-------------------------------------------------\")\n","            tp = true_a_k\n","            fp = all_n_k-true_n_k\n","            fn = all_a_k-true_a_k\n","            tn = true_n_k\n","            confusion_matrix = np.array([[tn, fn],[fp,tp]])\n","            #sns.heatmap(confusion_matrix/np.sum(confusion_matrix), annot=True, fmt='.2%', cmap='Greens')\n","            tot_conf_matrix += confusion_matrix\n","        \n","        y_axis_labels = [\"predicted normal\", \"predicted anomaly\"]\n","        x_axis_labels = [\"true normal\", \"true anomaly\"]\n","        sns.heatmap(tot_conf_matrix/np.sum(tot_conf_matrix), xticklabels=x_axis_labels, yticklabels=y_axis_labels, annot=True, fmt='.2%', cmap='Greens')\n","            \n","            "]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Dataset"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["> Just to have a visual feedback and test our code, we plot some samples from the **train** set (only *normal* samples) and **test** set (*normal* and *anomalous*)."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["hparams = asdict(Hparams())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["MVTec_Data = MVTec_DataModule(hparams)\n","# to setup it takes ~3 minutes\n","MVTec_Data.setup()\n","print(len(MVTec_Data.data_train)) # -->  3629 images\n","print(len(MVTec_Data.data_test)) # -->  1258+467=1725 images\n","print(\"TOTAL: \"+str(len(MVTec_Data.data_train)+len(MVTec_Data.data_test))+\" industrial images\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# depending on python version you can use --> data = iter(dataloader).next() or\n","#                                             data = next(iter(dataloader))\n","batch = next(iter(MVTec_Data.train_dataloader()))\n","plot_objects(MVTec_DataModule.denormalize(batch[\"img\"][0:40]), images_per_row=8, title=\"Industrial images from training dataset\")\n","batch2 = next(iter(MVTec_Data.val_dataloader()))\n","plot_objects(MVTec_DataModule.denormalize(batch2[\"img\"][0:40]), images_per_row=8, title=\"Industrial images from validation dataset\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["> âš¡ During our implementation we also tried an additional data extraction strategy in order to make ***data.setup()*** more efficient. <br> At the beginning we thought the slowness of the operation was induced by the many folder accesses and as a result the dataset folder structure is been modified. <br> Unfortunately *NO IMPROVEMENTS* were achieved. In fact the lack of efficiency came from the *image transformations*!"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Autoencoders - **AE**"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Baseline - *CNN AE*"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# settings for the logger working in a team\n","mixer = False # to identify if it is a mixer or not, during the performance evaluation\n","team_name = \"eai_project\"\n","project_name = \"EAI_Anomaly_Detection\"\n","version_name = \"baseline\"\n","run = wandb.init(entity=team_name, project=project_name, name = version_name, mode = \"online\")\n","\n","ae_hparams = asdict(Hparams())\n","data = MVTec_DataModule(ae_hparams)\n","model = AE(ae_hparams)\n","trainer = train_model(data, model, experiment_name = version_name, \\\n","    patience=20, metric_to_monitor=\"f1_score\", mode=\"max\", epochs = 100)\n","\n","wandb.finish()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### CNN Advanced AE - ***CO**ntractive + **DE**noising*"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# settings for the logger working in a team\n","mixer = False\n","team_name = \"eai_project\"\n","project_name = \"EAI_Anomaly_Detection\"\n","# to edit \n","version_name = \"CODE_AE\"\n","run = wandb.init(entity=team_name, project=project_name, name = version_name, mode = \"online\")\n","\n","ae_hparams = asdict(Hparams())\n","data = MVTec_DataModule(ae_hparams)\n","model = CODE_AE(ae_hparams)\n","trainer = train_model(data,model, experiment_name = version_name, \\\n","    patience=30, metric_to_monitor=\"f1_score\", mode=\"max\", epochs = 100)\n","\n","wandb.finish()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Mixer AE"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# settings for the logger working in a team\n","mixer = True\n","team_name = \"eai_project\"\n","project_name = \"EAI_Anomaly_Detection\"\n","# to edit \n","version_name = \"mixer_AE\"\n","run = wandb.init(entity=team_name, project=project_name, name = version_name, mode = \"online\")\n","\n","ae_hparams = asdict(Hparams())\n","data = MVTec_DataModule(ae_hparams)\n","model = Mixer_AE(ae_hparams)\n","trainer = train_model(data,model, experiment_name = version_name, \\\n","    patience=20, metric_to_monitor=\"f1_score\", mode=\"max\", epochs = 150)\n","\n","wandb.finish()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Test and analysis"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["load_ckpt = True\n","if load_ckpt:\n","    best_ckpt = \"models/CODE_AE-epoch=05-f1_score=0.3834.ckpt\"\n","    model = AE.load_from_checkpoint(best_ckpt, strict=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["batch = iter(data.train_dataloader()).next()\n","plot_objects(MVTec_DataModule.denormalize(batch[\"img\"][0:40]), images_per_row=8, title=\"Industrial images from training dataset\")\n","\n","if mixer:\n","    batch_recon, _ = model(batch[\"img\"])\n","else:\n","    batch_recon = model(batch[\"img\"])\n","plot_objects(MVTec_DataModule.denormalize(batch_recon[0:40]), images_per_row=8, title=\"Industrial images from training dataset (reconstructed)\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# if we want to test without training we need to setup the data\n","ae_hparams = asdict(Hparams())\n","data = MVTec_DataModule(ae_hparams)\n","data.setup()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# performance evaluation\n","performance_evaluation(model, data)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["sYnPaW3xqB76","o_pOiPmDqB78","UM9r2JPLqB79","dWYN7dXdqB7_","-6AfNu4BqB8A","8qebcYffqB8A","jGyjEQYeqB8B","3rN7DegMJpJB","P8ThCPp6Jt5c","7_K0zpGyqB8H","iCFsRmN9qB8I"],"provenance":[],"toc_visible":true},"gpuClass":"standard","kernelspec":{"display_name":"sappia","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"},"vscode":{"interpreter":{"hash":"5f06e66338bb5301debc8a4cff3b178f3ee2a0c1aca00670585ce1ed8b6c95da"}}},"nbformat":4,"nbformat_minor":0}
