{"cells":[{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["from typing import Any, Union, List, Optional\n","import os\n","from dataclasses import dataclass, asdict\n","\n","import torch\n","from PIL import Image\n","from torchvision import transforms\n","from torch.utils.data import DataLoader, Dataset\n","import pytorch_lightning as pl"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["# function for generating unique IDs!\n","def uniqueid():\n","\tseed = 0\n","\twhile True:\n","\t\tyield seed\n","\t\tseed += 1\n","\n","class MVTec:\n","\tdef __init__(self, images_folder: str, train_or_test: str):\n","\t\t\n","\t\tself.data = {}\n","\t\tself.train_or_test = train_or_test\n","\t\tid_generator = uniqueid()\n","\n","\t\tclass_folder_list = []\n","\t\tfor f in [images_folder+e for e in os.listdir(images_folder)]: # \"/home/lavallone/Desktop/EAI_Anomaly_Detection/data/\"\n","\t\t\tif os.path.isdir(f):\n","\t\t\t\tclass_folder_list.append(f)\n","\t\t\n","\t\tfor f in class_folder_list:\n","\t\t\tfor folder in os.listdir(f):\n","\t\t\t\tif folder==\"train\" and self.train_or_test==\"train\":\n","\t\t\t\t\tfor image_path in [f+\"/\"+folder+\"/good/\"+e for e in os.listdir(f+\"/\"+folder+\"/good/\")]:\n","\t\t\t\t\t\tself.data[str(next(id_generator))] = {\"image_path\" : image_path}\n","\t\t\t\tif folder==\"test\" and self.train_or_test==\"test\":\n","\t\t\t\t\tfor t in os.listdir(f+\"/\"+folder):\n","\t\t\t\t\t\tif t==\"good\":\n","\t\t\t\t\t\t\tfor image_path in [f+\"/\"+folder+\"/\"+t+\"/\"+e for e in os.listdir(f+\"/\"+folder+\"/\"+t+\"/\")]:\n","\t\t\t\t\t\t\t\tself.data[str(next(id_generator))] = {\"image_path\" : image_path, \"label\" : 0}\n","\t\t\t\t\t\telse:\n","\t\t\t\t\t\t\tfor image_path in [f+\"/\"+folder+\"/\"+t+\"/\"+e for e in os.listdir(f+\"/\"+folder+\"/\"+t+\"/\")]:\n","\t\t\t\t\t\t\t\tself.data[str(next(id_generator))] = {\"image_path\" : image_path, \"label\" : 1}\n"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["class MVTec_Dataset(Dataset):\n","\tdef __init__(self, MVTec):\n","\t\tself.data = self.make_data(MVTec)\n","\n","\tdef make_data(self, MVTec):\n","\t\ttransform = transforms.Compose([ # classica trasformazione per immagini\n","\t\t\ttransforms.Resize((224, 224)),\n","\t\t\ttransforms.ToTensor()\n","\t\t])\n","\t\tdata = list()\n","\t\tfor k in MVTec.data:\n","\t\t\titem = dict()\n","\t\t\titem[\"id\"] = k\n","\t\t\timg_pth = MVTec.data[k][\"image_path\"]\n","\t\t\titem[\"img\"] = transform(Image.open(img_pth).convert('RGB'))\n","\t\t\tif MVTec.train_or_test == \"test\":\n","\t\t\t\titem[\"label\"] = MVTec.data[k][\"label\"]\n","\t\t\tdata.append(item)\n","\t\treturn data\n","\n","\tdef __len__(self):\n","\t\treturn len(self.data)\n","\n","\tdef __getitem__(self, idx):\n","\t\treturn self.data[idx]\n","\n","\n","class MVTec_DataModule(pl.LightningDataModule):\n","    def __init__(self, hparams: dict, train_MVTec: Any, test_MVTec: Any) -> None:\n","        super().__init__()\n","        self.save_hyperparameters(hparams)\n","        self.train_MVTec = train_MVTec\n","        self.test_MVTec = test_MVTec\n","\n","    def setup(self, stage: Optional[str] = None) -> None:\n","        # TRAIN\n","        self.data_train = MVTec_Dataset(self.train_MVTec)\n","        # TEST\n","        self.data_test = MVTec_Dataset(self.test_MVTec)\n","\n","    def train_dataloader(self):\n","        return DataLoader(\n","            self.data_train,\n","            batch_size=self.hparams.batch_size,\n","            shuffle=True,\n","            num_workers=self.hparams.n_cpu,\n","            collate_fn=self.collate_train,\n","            #pin_memory=True,\n","            persistent_workers=True\n","        )\n","\n","    def val_dataloader(self):\n","        return DataLoader(\n","            self.data_test,\n","            batch_size=self.hparams.batch_size,\n","            shuffle=False,\n","            num_workers=self.hparams.n_cpu,\n","            collate_fn=self.collate_test,\n","            #pin_memory=True,\n","            persistent_workers=True\n","        )\n","        \n","    def collate_train(self, batch):\n","        batch_out = dict()\n","        batch_out[\"id\"] = [sample[\"id\"] for sample in batch]\n","        batch_out[\"img\"] = torch.stack([sample[\"img\"] for sample in batch], dim=0)\n","        return batch_out\n","    \n","    def collate_test(self, batch):\n","        batch_out = dict()\n","        batch_out[\"id\"] = [sample[\"id\"] for sample in batch]\n","        batch_out[\"img\"] = torch.stack([sample[\"img\"] for sample in batch], dim=0) \n","        batch_out[\"label\"] = [sample[\"label\"] for sample in batch]\n","        return batch_out"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["train_MVTec = MVTec(\"/home/lavallone/Desktop/EAI_Anomaly_Detection/data/\", \"train\")\n","test_MVTec = MVTec(\"/home/lavallone/Desktop/EAI_Anomaly_Detection/data/\", \"test\")"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of images in train set:\n","3629\n","Number of images in test set:\n","1725\n","In TOTAL:\n","5354\n"]}],"source":["print(\"Number of images in train set:\")\n","a = len([ k for k,v in train_MVTec.data.items()])\n","print(a)\n","print(\"Number of images in test set:\")\n","b = len([ k for k,v in test_MVTec.data.items()])\n","print(b)\n","print(\"In TOTAL:\")\n","print(a+b)"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["@dataclass\n","class HParams():\n","    # dataset stuff\n","    batch_size: int = 256 # 256\n","    n_cpu: int = 2 # 2 for colab\n","    lr: int = 3e-4\n","    wd: int = 0\n","\n","hparams = asdict(HParams())"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["data = MVTec_DataModule(hparams, train_MVTec, test_MVTec)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["sYnPaW3xqB76","o_pOiPmDqB78","UM9r2JPLqB79","dWYN7dXdqB7_","-6AfNu4BqB8A","8qebcYffqB8A","jGyjEQYeqB8B","3rN7DegMJpJB","P8ThCPp6Jt5c","7_K0zpGyqB8H","iCFsRmN9qB8I"],"provenance":[],"toc_visible":true},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.10.4 ('sappia')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"},"vscode":{"interpreter":{"hash":"5f06e66338bb5301debc8a4cff3b178f3ee2a0c1aca00670585ce1ed8b6c95da"}}},"nbformat":4,"nbformat_minor":0}
